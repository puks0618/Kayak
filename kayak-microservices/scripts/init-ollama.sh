#!/bin/bash

# Initialize Ollama with required models
# This script runs after Ollama container starts

echo "ğŸ¤– Initializing Ollama..."

# Wait for Ollama to be ready
until curl -s http://localhost:11434/api/tags > /dev/null 2>&1; do
    echo "â³ Waiting for Ollama to start..."
    sleep 2
done

echo "âœ… Ollama is ready!"

# Pull the llama3.2 model
echo "ğŸ“¥ Pulling llama3.2 model..."
docker exec kayak-ollama ollama pull llama3.2

echo "âœ… Model pulled successfully!"

# Verify model is available
echo "ğŸ” Verifying models..."
docker exec kayak-ollama ollama list

echo "âœ… Ollama initialization complete!"
